# ğŸ§ª Test Suite - Shipments Processing Platform

Esta suite de tests proporciona cobertura completa para validar todo el flujo desde la carga del JSON hasta el envÃ­o del email con URLs firmadas.

## ğŸ“‹ Estructura de Tests

```
tests/
â”œâ”€â”€ conftest.py                     # ConfiguraciÃ³n global y fixtures
â”œâ”€â”€ unit/                          # Tests unitarios por servicio
â”‚   â”œâ”€â”€ test_division_service.py   # Tests del Division Service
â”‚   â”œâ”€â”€ test_image_processing_service.py # Tests del Image Processing Service
â”‚   â””â”€â”€ test_email_service.py      # Tests del Email Service
â”œâ”€â”€ integration/                   # Tests de integraciÃ³n
â”‚   â””â”€â”€ test_end_to_end_flow.py   # Tests end-to-end completos
â””â”€â”€ README.md                     # Esta documentaciÃ³n
```

## ğŸ¯ Tipos de Tests

### Unit Tests (Pruebas Unitarias)
- **Division Service**: Valida divisiÃ³n de JSON, validaciÃ³n de archivos, manejo de eventos
- **Image Processing Service**: Valida procesamiento de imÃ¡genes, creaciÃ³n de ZIPs, URLs firmadas
- **Email Service**: Valida envÃ­o de emails, templates, notificaciones

### Integration Tests (Pruebas de IntegraciÃ³n)
- **End-to-End Flow**: Valida el flujo completo desde JSON hasta email
- **Error Scenarios**: Manejo de errores y recuperaciÃ³n
- **Performance Tests**: VerificaciÃ³n de tiempos de respuesta

## ğŸš€ EjecuciÃ³n de Tests

### Usando el script de automatizaciÃ³n:

```bash
# Hacer ejecutable el script
chmod +x run-tests.sh

# Ejecutar todos los tests
./run-tests.sh all

# Ejecutar tests unitarios Ãºnicamente
./run-tests.sh unit

# Ejecutar tests de integraciÃ³n
./run-tests.sh integration

# Ejecutar tests end-to-end
./run-tests.sh e2e

# Ejecutar con cobertura y en paralelo
./run-tests.sh all --coverage --parallel

# Ejecutar tests especÃ­ficos con marcadores
./run-tests.sh --marker "email"
```

### Usando pytest directamente:

```bash
# Todos los tests
pytest tests/ -v

# Tests unitarios solamente
pytest tests/unit/ -v

# Tests end-to-end con output detallado
pytest tests/integration/test_end_to_end_flow.py -v -s

# Tests con cobertura
pytest tests/ --cov=services --cov-report=html

# Tests en paralelo
pytest tests/ -n auto
```

## ğŸ·ï¸ Marcadores de Tests

Los tests estÃ¡n categorizados con marcadores para facilitar la ejecuciÃ³n selectiva:

- `unit`: Tests unitarios
- `integration`: Tests de integraciÃ³n  
- `e2e`: Tests end-to-end
- `smoke`: Tests de smoke rÃ¡pidos
- `slow`: Tests que tardan mÃ¡s de 5 segundos
- `performance`: Tests de rendimiento
- `database`: Tests que requieren base de datos
- `storage`: Tests que requieren cloud storage
- `email`: Tests que requieren funcionalidad de email

## ğŸ“Š Cobertura de Tests

### Division Service
- âœ… Health check endpoints
- âœ… Procesamiento de archivos JSON
- âœ… ValidaciÃ³n de estructura de archivos
- âœ… DivisiÃ³n en paquetes
- âœ… Manejo de errores y Pub/Sub
- âœ… Consulta de estado de procesamiento

### Image Processing Service
- âœ… Health check endpoints
- âœ… Procesamiento de paquetes de imÃ¡genes
- âœ… Descarga y agrupaciÃ³n de imÃ¡genes
- âœ… CreaciÃ³n de archivos ZIP
- âœ… GeneraciÃ³n de URLs firmadas
- âœ… ProgramaciÃ³n y ejecuciÃ³n de limpieza
- âœ… Manejo de errores

### Email Service
- âœ… Health check endpoints
- âœ… EnvÃ­o de emails de completitud
- âœ… Notificaciones de error
- âœ… Emails personalizados
- âœ… GestiÃ³n de templates
- âœ… EstadÃ­sticas de envÃ­o
- âœ… Manejo de mensajes Pub/Sub

### End-to-End Flow
- âœ… Flujo completo de procesamiento
- âœ… Procesamiento en paralelo
- âœ… Manejo de errores y recuperaciÃ³n
- âœ… Escenarios de Ã©xito parcial
- âœ… OrquestaciÃ³n con Cloud Workflows
- âœ… VerificaciÃ³n de URLs firmadas
- âœ… ValidaciÃ³n de emails enviados

## ğŸ”§ ConfiguraciÃ³n de Testing

### Variables de Entorno
Los tests utilizan las siguientes variables de entorno:

```bash
TESTING=true
GCP_PROJECT_ID=test-project
GCS_BUCKET=test-bucket
DB_HOST=localhost
DB_NAME=test_db
SMTP_HOST=smtp.test.com
```

### Mocks y Fixtures
- **Storage Mock**: Simula operaciones de Google Cloud Storage
- **Database Mock**: Simula conexiones y operaciones de PostgreSQL
- **SMTP Mock**: Simula servidor de email
- **Pub/Sub Mock**: Simula mensajerÃ­a
- **Workflow Mock**: Simula ejecuciones de Cloud Workflows

## ğŸ“ˆ MÃ©tricas y Reportes

### Coverage Report
DespuÃ©s de ejecutar tests con cobertura, se genera:
- **HTML Report**: `htmlcov/index.html`
- **Terminal Report**: Mostrado en consola
- **Objetivo**: MÃ­nimo 85% de cobertura

### Performance Metrics
Los tests de rendimiento validan:
- **DivisiÃ³n**: < 5 segundos
- **Procesamiento de imÃ¡genes**: < 30 segundos  
- **EnvÃ­o de email**: < 5 segundos
- **Flujo completo**: < 45 segundos

## ğŸ› ï¸ Troubleshooting

### Errores Comunes

**ImportError en mÃ³dulos de servicios:**
```bash
# Asegurar que PYTHONPATH incluye shared_utils
export PYTHONPATH="${PYTHONPATH}:$(pwd)/services/shared_utils/src"
```

**Tests fallan por dependencias:**
```bash
# Instalar dependencias de testing
pip install pytest pytest-cov pytest-xdist pytest-asyncio
```

**Problemas con tests async:**
```bash
# Verificar configuraciÃ³n en pytest.ini
asyncio_mode = auto
```

### Debug de Tests

Para debuggear tests especÃ­ficos:
```bash
# Ejecutar test individual con output completo
pytest tests/unit/test_division_service.py::TestProcessFileEndpoint::test_process_file_success -v -s

# Ejecutar con breakpoints
pytest tests/unit/test_division_service.py -v -s --pdb

# Ver logs detallados
pytest tests/ -v -s --log-cli-level=DEBUG
```

## ğŸ“ Mejores PrÃ¡cticas

### Escritura de Tests
1. **Nombres descriptivos**: `test_process_file_with_valid_json_succeeds`
2. **Arrange-Act-Assert**: Estructura clara en 3 secciones
3. **Un concepto por test**: Cada test valida un escenario especÃ­fico
4. **Mocks apropiados**: Mock solo dependencias externas
5. **Fixtures reutilizables**: Compartir setup comÃºn

### OrganizaciÃ³n
1. **Agrupar por funcionalidad**: Usar clases para agrupar tests relacionados
2. **Marcadores consistentes**: Usar markers para categorizar
3. **Fixtures especÃ­ficas**: Crear fixtures por contexto de uso
4. **DocumentaciÃ³n**: Docstrings explicando quÃ© valida cada test

### Performance
1. **Paralelo para suites grandes**: Usar `pytest-xdist` para tests independientes
2. **Fixtures con scope**: `session`, `module`, `class` para setup costoso
3. **Mocks ligeros**: Evitar lÃ³gica compleja en mocks
4. **Cleanup apropiado**: Limpiar recursos despuÃ©s de tests

## ğŸ”„ CI/CD Integration

Los tests estÃ¡n diseÃ±ados para integrarse con pipelines de CI/CD:

```yaml
# Ejemplo para GitHub Actions
- name: Run Tests
  run: |
    ./run-tests.sh all --coverage --parallel
    
- name: Upload Coverage
  uses: codecov/codecov-action@v1
  with:
    file: ./coverage.xml
```

## ğŸ“š Recursos Adicionales

- [Pytest Documentation](https://docs.pytest.org/)
- [Google Cloud Testing](https://cloud.google.com/docs/testing)
- [Python Mock Library](https://docs.python.org/3/library/unittest.mock.html)
- [Async Testing](https://pytest-asyncio.readthedocs.io/)

---

**Nota**: Esta suite de tests asegura que el Shipments Processing Platform funciona correctamente desde la carga del JSON hasta la entrega del email con URLs firmadas, cubriendo todos los escenarios de Ã©xito y error en una arquitectura empresarial robusta.
